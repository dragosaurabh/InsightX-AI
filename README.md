# InsightX AI

> **Conversational analytics for payments: ask plain English, get precise, explainable answers.**

InsightX AI is a production-ready conversational analytics platform for digital payment data. It enables leadership teams to query transaction data using natural language and receive accurate, explainable insights backed by deterministic analysis.

## âœ¨ Features

- **Natural Language Queries**: Ask questions in plain English
- **Intent Extraction**: Powered by Google Gemini for accurate understanding
- **Deterministic Analysis**: DuckDB-backed for fast, precise computations
- **Explainability**: Every response includes SQL used, method explanation, and key statistics
- **Session Context**: Maintains conversation history for follow-ups
- **No Hallucination**: LLM uses only computed results - never invents numbers

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js UI    â”‚â”€â”€â”€â”€â–¶â”‚              FastAPI Backend             â”‚
â”‚   (Chat Window) â”‚     â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                        â”‚  â”‚ LLM Service â”‚    â”‚ Analysis Serviceâ”‚  â”‚
                        â”‚  â”‚  (Gemini)   â”‚    â”‚    (DuckDB)     â”‚  â”‚
                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 20+
- Google Gemini API key

### 1. Clone and Setup

```bash
git clone https://github.com/your-org/insightx-ai.git
cd insightx-ai

# Copy environment file
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY
```

### 2. Generate Sample Data

```bash
cd scripts
python ingest_sample_data.py --rows 50000
# Creates: data/sample_transactions_50k.csv
```

### 3. Start Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Update DATA_PATH in .env to point to your CSV
uvicorn app.main:app --reload --port 8000
```

### 4. Start Frontend

```bash
cd frontend/nextjs-app
npm install
npm run dev
```

Open http://localhost:3000 and start asking questions!

## ğŸ³ Docker Quick Start

```bash
# Generate sample data first
python scripts/ingest_sample_data.py --rows 50000

# Set your API key in .env
echo "GEMINI_API_KEY=your_key_here" > .env

# Start with Docker Compose
docker compose -f infra/docker-compose.yml up --build
```

Access the app at http://localhost:3000

## ğŸ“ Sample Queries

Try these example queries:

1. "What is the overall failure rate in the last 30 days?"
2. "Compare failure rate on Android vs iOS"
3. "Show average transaction amount by category"
4. "What are the top 3 failure codes?"
5. "Provide an executive summary for January 2026"

See [docs/sample_queries.json](docs/sample_queries.json) for 15+ queries with expected responses.

## ğŸ”§ Configuration

| Variable | Description | Default |
|----------|-------------|---------|
| `GEMINI_API_KEY` | Google Gemini API key | *Required* |
| `GEMINI_MODEL` | Gemini model version | `gemini-1.5-flash` |
| `DATA_PATH` | Path to transaction CSV | `./data/transactions.csv` |
| `FRONTEND_ORIGIN` | Frontend URL for CORS | `http://localhost:3000` |
| `MAX_CONTEXT_TURNS` | Session history length | `6` |
| `RATE_LIMIT_PER_MIN` | LLM calls per minute | `10` |
| `REDIS_URL` | Redis URL (optional) | *In-memory* |

## ğŸ§ª Testing

```bash
cd backend

# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_analysis.py -v

# Run with coverage
pytest tests/ --cov=app --cov-report=html
```

## ğŸ“ Project Structure

```
insightx-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/          # API endpoints
â”‚   â”‚   â”œâ”€â”€ models/       # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ prompts/      # LLM prompt templates
â”‚   â”‚   â””â”€â”€ services/     # Business logic
â”‚   â”œâ”€â”€ tests/            # Unit & integration tests
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ nextjs-app/
â”‚   â”‚   â”œâ”€â”€ components/   # React components
â”‚   â”‚   â”œâ”€â”€ lib/          # API client
â”‚   â”‚   â””â”€â”€ pages/        # Next.js pages
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ nginx.conf
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ ingest_sample_data.py
â””â”€â”€ docs/
    â”œâ”€â”€ DEPLOY.md
    â”œâ”€â”€ ROUND1_CONCEPT.md
    â””â”€â”€ sample_queries.json
```

## ğŸ“š Documentation

- [Deployment Guide](docs/DEPLOY.md) - Production deployment instructions
- [Round 1 Concept](docs/ROUND1_CONCEPT.md) - Hackathon submission document
- [Security Guidelines](docs/SECURITY.md) - Security best practices

## ğŸ”’ Security

- API keys stored in environment variables only
- CORS restricted to frontend origin
- Rate limiting on API endpoints
- Non-root Docker containers
- Input sanitization on all user inputs

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

Built with â¤ï¸ for the InsightX AI Hackathon
